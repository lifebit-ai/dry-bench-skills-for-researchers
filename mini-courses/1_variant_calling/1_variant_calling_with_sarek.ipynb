{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. nf-core/sarek: An end-to-end variant calling nextflow workflow for sarek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/nf-core/sarek/blob/master/docs/images/sarek_workflow.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline configuration logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Select `step` \n",
    "\n",
    "**Available:**\n",
    "\n",
    "- mapping\n",
    "- prepare_recalibration\n",
    "- recalibrate\n",
    "- variant_calling\n",
    "\n",
    "\n",
    "**Example configuration options**\n",
    "\n",
    "```bash\n",
    "nextflow run main.nf --step mapping ...\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Select Variant Calling `tools`\n",
    "\n",
    "**Available:**\n",
    "\n",
    "Germline:\n",
    " - GATK HaplotypeCaller\n",
    " - mpileup\n",
    " - FreeBayes\n",
    " - Manta \n",
    " - TIDDIT\n",
    "\n",
    "Somatic:\n",
    " - GATK Mutect2\n",
    " - Strelka\n",
    " - FreeBayes\n",
    " - ASCAT\n",
    " - CNVkit\n",
    " - ControlFREEC \n",
    " - Manta \n",
    " - MSIsensor\n",
    " \n",
    "\n",
    "**Annotation:**\n",
    " - snpEff\n",
    " - VEP\n",
    "\n",
    "**Example configuration options**\n",
    "\n",
    "```bash\n",
    "nextflow run main.nf --tools HaplotypeCaller,Strelka,VEP ...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare `input` files\n",
    "\n",
    "Based on the selected `step` the respective input file should be created accordingly to contain either metadata for the samples and the file locations \n",
    "\n",
    "- FASTQ\n",
    "- BAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. --input &lt;FASTQ&gt; --step mapping\n",
    "\n",
    "The `TSV` file to start with the mapping step (`--step mapping`) with paired-end `FASTQs` should contain the columns:\n",
    "\n",
    "`subject sex status sample lane fastq1 fastq2`\n",
    "\n",
    "In this example (`example_fastq.tsv`), there are 3 read groups.\n",
    "\n",
    "| | | | | | |\n",
    "|-|-|-|-|-|-|\n",
    "|SUBJECT_ID|XX|0|SAMPLE_ID|1|/samples/normal1_1.fastq.gz|/samples/normal1_2.fastq.gz|\n",
    "|SUBJECT_ID|XX|0|SAMPLE_ID|2|/samples/normal2_1.fastq.gz|/samples/normal2_2.fastq.gz|\n",
    "|SUBJECT_ID|XX|0|SAMPLE_ID|3|/samples/normal3_1.fastq.gz|/samples/normal3_2.fastq.gz|\n",
    "\n",
    "```bash\n",
    "--input example_fastq.tsv\n",
    "```\n",
    "\n",
    "Or, for a normal/tumor pair:\n",
    "\n",
    "In this example (`example_pair_fastq.tsv`), there are 3 read groups for the normal sample and 2 for the tumor sample.\n",
    "\n",
    "| | | | | | |\n",
    "|-|-|-|-|-|-|\n",
    "|SUBJECT_ID|XX|0|SAMPLE_ID1|1|/samples/normal1_1.fastq.gz|/samples/normal1_2.fastq.gz|\n",
    "|SUBJECT_ID|XX|0|SAMPLE_ID1|2|/samples/normal2_1.fastq.gz|/samples/normal2_2.fastq.gz|\n",
    "|SUBJECT_ID|XX|0|SAMPLE_ID1|3|/samples/normal3_1.fastq.gz|/samples/normal3_2.fastq.gz|\n",
    "|SUBJECT_ID|XX|1|SAMPLE_ID2|1|/samples/tumor1_1.fastq.gz|/samples/tumor1_2.fastq.gz|\n",
    "|SUBJECT_ID|XX|1|SAMPLE_ID2|2|/samples/tumor2_1.fastq.gz|/samples/tumor2_2.fastq.gz|\n",
    "\n",
    "```bash\n",
    "--input example_pair_fastq.tsv\n",
    "```\n",
    "\n",
    "_source: [sarek docs, mapping step](https://github.com/lifebit-ai/sarek/blob/google-optim/docs/usage.md#--input-fastq---step-mapping)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. --input &lt;TSV&gt; --step variant_calling\n",
    "\n",
    "To start from the variant calling step (`--step variant_calling`), a `TSV` file needs to be given as input containing the paths to the `recalibrated BAM` file and the associated index.\n",
    "The `Sarek`-generated `TSV` file is stored under `results/Preprocessing/TSV/recalibrated.tsv` and will automatically be used as an input when specifying the parameter `--step variant_calling`.\n",
    "\n",
    "The `TSV` file should contain the columns:\n",
    "\n",
    "`subject sex status sample bam bai`\n",
    "\n",
    "Here is an example for two samples from the same subject:\n",
    "\n",
    "| | | | | | |\n",
    "|-|-|-|-|-|-|\n",
    "|SUBJECT_ID|XX|0|SAMPLE_ID|/samples/normal.recal.bam|/samples/normal.recal.bai|\n",
    "\n",
    "Or, for a normal/tumor pair:\n",
    "\n",
    "| | | | | | |\n",
    "|-|-|-|-|-|-|\n",
    "|SUBJECT_ID|XX|0|SAMPLE_ID1|/samples/normal.recal.bam|/samples/normal.recal.bai|\n",
    "|SUBJECT_ID|XX|1|SAMPLE_ID2|/samples/tumor.recal.bam|/samples/tumor.recal.bai|\n",
    "\n",
    "source: [sarek docs, mapping step](https://github.com/lifebit-ai/sarek/blob/google-optim/docs/usage.md#--input-tsv---step-variant_calling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Running examples in the JAX CloudOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Step mapping example, start from FASTQ files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Parameters taken from smmall example configuration files to run in shorter time:_\n",
    "\n",
    "\n",
    "\n",
    "![](assets/mapping.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce the analysis in JAX CloudOS and inspect the parameters used you can click the `Clone` button in the above page:\n",
    "\n",
    "\n",
    "## https://cloudos.lifebit.ai/app/jobs/605c93e7cc2b270112468a42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equivalent command line code snippet to reproduce locally is:\n",
    "\n",
    "\n",
    "```bash\n",
    "nextflow run https://github.com/lifebit-ai/sarek -r d1c7484 \\\n",
    "--config 'conf/local.config' \\\n",
    "--input 'https://raw.githubusercontent.com/nf-core/test-datasets/sarek/testdata/tsv/tiny-manta-https.tsv' \\\n",
    "--step 'mapping' \\\n",
    "--genomes_base 'https://raw.githubusercontent.com/nf-core/test-datasets/sarek/reference' \\\n",
    "--genome 'smallGRCh37' \\\n",
    "--igenomes_ignore true \\\n",
    "--max_memory '16.GB' \\\n",
    "--max_cpus 6\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Step mapping example, start from FASTQ files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Parameters taken from smmall example configuration files to run in shorter time:_\n",
    "\n",
    "\n",
    "\n",
    "![](assets/variant_calling.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce the analysis in JAX CloudOS and inspect the parameters used you can click the `Clone` button in the above page:\n",
    "\n",
    "\n",
    "## https://cloudos.lifebit.ai/app/jobs/605c967acc2b2701124699d4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nextflow run https://github.com/lifebit-ai/sarek \\\n",
    "--config 'conf/local.config' \\\n",
    "--input 'https://raw.githubusercontent.com/nf-core/test-datasets/sarek/testdata/tsv/tiny-recal-pair-https.tsv' \\\n",
    "--step 'variantcalling' \\\n",
    "--tools 'Haplotypecaller' \\\n",
    "--genomes_base 'https://raw.githubusercontent.com/nf-core/test-datasets/sarek/reference' \\\n",
    "--genome 'smallGRCh37' \\\n",
    "--igenomes_ignore true \\\n",
    "--generate_gvcf false \\\n",
    "--max_memory '16.GB' \\\n",
    "--max_cpus 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Execution across Cloud, Clusters and local machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same workflow can be ran with minimal configuration adjustments across laptops, SLURM managed clusters and different cloud vendors.\n",
    "\n",
    "Notice above the commands:\n",
    "\n",
    "\n",
    "For Google Cloud we can use a specific configuration file:\n",
    "\n",
    "\n",
    "```bash\n",
    "nextflow run https://github.com/lifebit-ai/sarek \\\n",
    "--config 'conf/local.config'\n",
    "```\n",
    "\n",
    "For SLURM managed another:\n",
    "\n",
    "```bash\n",
    "nextflow run https://github.com/lifebit-ai/sarek \\\n",
    "--config 'conf/slurm.config'\n",
    "```\n",
    "\n",
    "And also for our local machine, eg. laptop:\n",
    "\n",
    "```bash\n",
    "nextflow run https://github.com/lifebit-ai/sarek \\\n",
    "--config 'conf/local.config'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This modification allows us to retain the rest parameters unchanged, allwing for swift change of execution environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C1 - SLURM Managed cluster\n",
    "\n",
    "The required files are 2:\n",
    "\n",
    "- a pbs submission script\n",
    "- Nextflow config eg. slurm.config\n",
    "\n",
    "\n",
    "#### Contents of pbs submission script\n",
    "\n",
    "\n",
    "```bash\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH -o logs.%j.out\n",
    "#SBATCH -e logs.%j.err\n",
    "#SBATCH --mail-type=END,FAIL\n",
    "#SBATCH --mail-user=$USER@my-org.org\n",
    "#SBATCH --mem=20000\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH -p compute\n",
    "#SBATCH -q batch\n",
    "#SBATCH -t 3-00:00:00 \n",
    "\n",
    "cd $SLURM_SUBMIT_DIR\n",
    "date;hostname;pwd\n",
    "\n",
    "module load singularity\n",
    "\n",
    "curl -fsSL https://get.nextflow.io | bash\n",
    "\n",
    "./nextflow run /absolut/path/to/pipeline/repo/main.nf --outdir ${SLURM_SUBMIT_DIR} --param1 param1_value\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents of nextflow config for SLURM managed cluster\n",
    "\n",
    "- Sungularity enabled\n",
    "\n",
    "```groovy\n",
    "/*\n",
    " * -------------------------------------------------\n",
    " *  Nextflow config file for running on a SLURM managed cluster\n",
    " * -------------------------------------------------\n",
    " */\n",
    "\n",
    "process {\n",
    "  executor = 'slurm'\n",
    "  beforeScript = 'module load singularity'\n",
    "}\n",
    "singularity {\n",
    "  enabled = true\n",
    "  autoMounts = true\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C2 - Google Cloud config\n",
    "\n",
    "#### Contents of config\n",
    "\n",
    "\n",
    "```groovy\n",
    "\n",
    "// This config is specific to google-life-science\n",
    "\n",
    "includeConfig 'base.config'\n",
    "\n",
    "google {\n",
    "    lifeSciences.bootDiskSize = 50.GB\n",
    "    lifeSciences.preemptible = true\n",
    "    zone = params.gls_zone\n",
    "    network = params.gls_network\n",
    "    subnetwork = params.gls_subnetwork\n",
    "}\n",
    "\n",
    "docker.enabled = true\n",
    "\n",
    "executor {\n",
    "    name = 'google-lifesciences'\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C3 - Local config for laptops\n",
    "\n",
    "#### Contents of config\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "/*\n",
    " * -------------------------------------------------\n",
    " *  Nextflow config file for running on a local machine eg. laptop\n",
    " * -------------------------------------------------\n",
    " */\n",
    "\n",
    "docker.enabled = true\n",
    "\n",
    "params {\n",
    "    executor = 'local'\n",
    "}\n",
    "\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
